{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function should be applied to a df containing the data for matches (aggregated or not) in the initial \n",
    "# clean format that we defined\n",
    "# THIS FUNCTION ORDERS DISTANCES AND CLUSTERS FROM HIGHGEST TO LOWEST\n",
    "def aggData(df):\n",
    "    distances = df.iloc[:, 6:12]\n",
    "    distances.fillna(-999)\n",
    "    centroids = df.iloc[:, 12:16]\n",
    "    centroids.fillna(-999)\n",
    "    clusters = df.iloc[:, 16:20].values\n",
    "    new_distances = np.sort(distances.values, axis=1)[:,::-1]\n",
    "    new_centroids = np.sort(centroids.values, axis=1)[:,::-1]\n",
    "    new_clusters = np.sort(clusters, axis=1)[:,::-1]\n",
    "    distances = distances.replace(-999, np.nan)\n",
    "    centroids = centroids.replace(-999, np.nan)\n",
    "    df.iloc[:, 6:12] = new_distances\n",
    "    df.iloc[:, 12:16] = new_centroids\n",
    "    df.iloc[:, 16:20] = new_clusters\n",
    "    df['agility']=np.where(df['strategy']!=df['strategy'].shift(-1), 1,0)\n",
    "    ranking = df['ranking']\n",
    "    df = df.drop('ranking', axis=1)\n",
    "    df.insert(len(df.columns), 'ranking', ranking)\n",
    "    df['cluster_A'] = df['cluster_A'] / df['n_alive']\n",
    "    df['cluster_B'] = df['cluster_B'] / df['n_alive']\n",
    "    df['cluster_C'] = df['cluster_C'] / df['n_alive']\n",
    "    df['cluster_D'] = df['cluster_D'] / df['n_alive']\n",
    "    df = df[df.n_alive > 0]\n",
    "    df = df.drop(['time','n_alive','in_aircraft'], axis=1)\n",
    "    df.loc[:,['distance1_2','distance1_3','distance1_4','distance2_3', 'distance2_4', 'distance3_4',\n",
    "              'distance_centroid1', 'distance_centroid2', 'distance_centroid3', 'distance_centroid4']] = df.loc[:,['distance1_2','distance1_3','distance1_4','distance2_3', 'distance2_4', 'distance3_4',\n",
    "                                                                                                                   'distance_centroid1', 'distance_centroid2', 'distance_centroid3', 'distance_centroid4']] / 100\n",
    "    df.loc[:, ['distance1_2','distance1_3','distance1_4','distance2_3', 'distance2_4', 'distance3_4',\n",
    "              'distance_centroid1', 'distance_centroid2', 'distance_centroid3', 'distance_centroid4']] = df.loc[:, ['distance1_2','distance1_3','distance1_4','distance2_3', 'distance2_4', 'distance3_4',\n",
    "                                                                                                                   'distance_centroid1', 'distance_centroid2', 'distance_centroid3', 'distance_centroid4']].applymap(lambda x:np.log(x) if x != 0 else 0)\n",
    "    means = df.groupby(['matchId', 'teamId']).mean().reset_index()\n",
    "    stds = df.groupby(['matchId', 'teamId']).std().reset_index()\n",
    "    means = means.fillna(99)\n",
    "    means = means.replace(np.inf, 0)\n",
    "    stds = stds.fillna(0)\n",
    "    new_df = pd.merge(stds, means, how = 'left', on=['matchId', 'teamId'])\n",
    "    new_df = new_df.drop(['n_players_x', 'ranking_x', 'agility_x'], axis=1)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:33: RuntimeWarning: invalid value encountered in log\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('combined_csv_1.csv')\n",
    "aggregated_df = aggData(df)\n",
    "df3 = pd.read_csv('combined_csv_4.csv')\n",
    "aggregated_df3 = aggData(df3)\n",
    "df2 = pd.read_csv('combined_csv_2.csv')\n",
    "aggregated_df2 = aggData(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_123 = pd.concat([aggregated_df, aggregated_df2,aggregated_df3],ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>ranking_y</td>    <th>  R-squared:         </th>  <td>   0.306</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.306</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1659.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 09 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:56:01</td>     <th>  Log-Likelihood:    </th> <td>-3.8617e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>116478</td>      <th>  AIC:               </th>  <td>7.724e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>116446</td>      <th>  BIC:               </th>  <td>7.727e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    31</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td> -197.1042</td> <td>   24.374</td> <td>   -8.087</td> <td> 0.000</td> <td> -244.878</td> <td> -149.331</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>teamId</th>               <td>    0.0906</td> <td>    0.003</td> <td>   35.936</td> <td> 0.000</td> <td>    0.086</td> <td>    0.096</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_2_x</th>        <td>   -1.1029</td> <td>    0.104</td> <td>  -10.592</td> <td> 0.000</td> <td>   -1.307</td> <td>   -0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_3_x</th>        <td>   -0.0682</td> <td>    0.125</td> <td>   -0.544</td> <td> 0.587</td> <td>   -0.314</td> <td>    0.178</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_4_x</th>        <td>    0.3344</td> <td>    0.080</td> <td>    4.173</td> <td> 0.000</td> <td>    0.177</td> <td>    0.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_3_x</th>        <td>    0.6773</td> <td>    0.098</td> <td>    6.914</td> <td> 0.000</td> <td>    0.485</td> <td>    0.869</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_4_x</th>        <td>   -1.2316</td> <td>    0.110</td> <td>  -11.170</td> <td> 0.000</td> <td>   -1.448</td> <td>   -1.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance3_4_x</th>        <td>    0.3712</td> <td>    0.076</td> <td>    4.903</td> <td> 0.000</td> <td>    0.223</td> <td>    0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid1_x</th> <td>    3.4789</td> <td>    0.044</td> <td>   79.137</td> <td> 0.000</td> <td>    3.393</td> <td>    3.565</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid2_x</th> <td>    1.1826</td> <td>    0.084</td> <td>   14.139</td> <td> 0.000</td> <td>    1.019</td> <td>    1.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid3_x</th> <td>   -1.3528</td> <td>    0.090</td> <td>  -14.957</td> <td> 0.000</td> <td>   -1.530</td> <td>   -1.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid4_x</th> <td>    1.3790</td> <td>    0.059</td> <td>   23.341</td> <td> 0.000</td> <td>    1.263</td> <td>    1.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_A_x</th>          <td>   11.6535</td> <td>    1.584</td> <td>    7.359</td> <td> 0.000</td> <td>    8.550</td> <td>   14.757</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_B_x</th>          <td>  -53.5794</td> <td>    1.724</td> <td>  -31.087</td> <td> 0.000</td> <td>  -56.957</td> <td>  -50.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_C_x</th>          <td>  -35.1410</td> <td>    1.444</td> <td>  -24.334</td> <td> 0.000</td> <td>  -37.971</td> <td>  -32.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_D_x</th>          <td>  -33.8434</td> <td>    1.728</td> <td>  -19.587</td> <td> 0.000</td> <td>  -37.230</td> <td>  -30.457</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_players_y</th>          <td>   -0.1873</td> <td>    0.140</td> <td>   -1.340</td> <td> 0.180</td> <td>   -0.461</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_2_y</th>        <td>    0.0853</td> <td>    0.004</td> <td>   23.282</td> <td> 0.000</td> <td>    0.078</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_3_y</th>        <td>    0.0195</td> <td>    0.010</td> <td>    2.049</td> <td> 0.040</td> <td>    0.001</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_4_y</th>        <td>   -0.0081</td> <td>    0.009</td> <td>   -0.880</td> <td> 0.379</td> <td>   -0.026</td> <td>    0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_3_y</th>        <td>    0.0314</td> <td>    0.003</td> <td>    9.620</td> <td> 0.000</td> <td>    0.025</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_4_y</th>        <td>    0.0389</td> <td>    0.004</td> <td>    9.535</td> <td> 0.000</td> <td>    0.031</td> <td>    0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance3_4_y</th>        <td>    0.0144</td> <td>    0.003</td> <td>    5.188</td> <td> 0.000</td> <td>    0.009</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid1_y</th> <td>   -0.0248</td> <td>    0.003</td> <td>   -7.460</td> <td> 0.000</td> <td>   -0.031</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid2_y</th> <td>   -0.0119</td> <td>    0.003</td> <td>   -4.565</td> <td> 0.000</td> <td>   -0.017</td> <td>   -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid3_y</th> <td>    0.0063</td> <td>    0.002</td> <td>    2.728</td> <td> 0.006</td> <td>    0.002</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid4_y</th> <td>   -0.0143</td> <td>    0.002</td> <td>   -6.809</td> <td> 0.000</td> <td>   -0.018</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_A_y</th>          <td>  200.1053</td> <td>   24.200</td> <td>    8.269</td> <td> 0.000</td> <td>  152.674</td> <td>  247.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_B_y</th>          <td>  219.0014</td> <td>   24.216</td> <td>    9.044</td> <td> 0.000</td> <td>  171.538</td> <td>  266.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_C_y</th>          <td>  216.0048</td> <td>   24.263</td> <td>    8.903</td> <td> 0.000</td> <td>  168.450</td> <td>  263.560</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_D_y</th>          <td>  228.0829</td> <td>   24.325</td> <td>    9.377</td> <td> 0.000</td> <td>  180.407</td> <td>  275.759</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agility_y</th>            <td>   31.5231</td> <td>    0.186</td> <td>  169.918</td> <td> 0.000</td> <td>   31.160</td> <td>   31.887</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>1575.065</td> <th>  Durbin-Watson:     </th> <td>   1.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2442.595</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.139</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 3.652</td>  <th>  Cond. No.          </th> <td>3.43e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 3.43e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              ranking_y   R-squared:                       0.306\n",
       "Model:                            OLS   Adj. R-squared:                  0.306\n",
       "Method:                 Least Squares   F-statistic:                     1659.\n",
       "Date:                Tue, 09 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        17:56:01   Log-Likelihood:            -3.8617e+05\n",
       "No. Observations:              116478   AIC:                         7.724e+05\n",
       "Df Residuals:                  116446   BIC:                         7.727e+05\n",
       "Df Model:                          31                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                 -197.1042     24.374     -8.087      0.000    -244.878    -149.331\n",
       "teamId                   0.0906      0.003     35.936      0.000       0.086       0.096\n",
       "distance1_2_x           -1.1029      0.104    -10.592      0.000      -1.307      -0.899\n",
       "distance1_3_x           -0.0682      0.125     -0.544      0.587      -0.314       0.178\n",
       "distance1_4_x            0.3344      0.080      4.173      0.000       0.177       0.491\n",
       "distance2_3_x            0.6773      0.098      6.914      0.000       0.485       0.869\n",
       "distance2_4_x           -1.2316      0.110    -11.170      0.000      -1.448      -1.015\n",
       "distance3_4_x            0.3712      0.076      4.903      0.000       0.223       0.520\n",
       "distance_centroid1_x     3.4789      0.044     79.137      0.000       3.393       3.565\n",
       "distance_centroid2_x     1.1826      0.084     14.139      0.000       1.019       1.346\n",
       "distance_centroid3_x    -1.3528      0.090    -14.957      0.000      -1.530      -1.176\n",
       "distance_centroid4_x     1.3790      0.059     23.341      0.000       1.263       1.495\n",
       "cluster_A_x             11.6535      1.584      7.359      0.000       8.550      14.757\n",
       "cluster_B_x            -53.5794      1.724    -31.087      0.000     -56.957     -50.201\n",
       "cluster_C_x            -35.1410      1.444    -24.334      0.000     -37.971     -32.311\n",
       "cluster_D_x            -33.8434      1.728    -19.587      0.000     -37.230     -30.457\n",
       "n_players_y             -0.1873      0.140     -1.340      0.180      -0.461       0.087\n",
       "distance1_2_y            0.0853      0.004     23.282      0.000       0.078       0.092\n",
       "distance1_3_y            0.0195      0.010      2.049      0.040       0.001       0.038\n",
       "distance1_4_y           -0.0081      0.009     -0.880      0.379      -0.026       0.010\n",
       "distance2_3_y            0.0314      0.003      9.620      0.000       0.025       0.038\n",
       "distance2_4_y            0.0389      0.004      9.535      0.000       0.031       0.047\n",
       "distance3_4_y            0.0144      0.003      5.188      0.000       0.009       0.020\n",
       "distance_centroid1_y    -0.0248      0.003     -7.460      0.000      -0.031      -0.018\n",
       "distance_centroid2_y    -0.0119      0.003     -4.565      0.000      -0.017      -0.007\n",
       "distance_centroid3_y     0.0063      0.002      2.728      0.006       0.002       0.011\n",
       "distance_centroid4_y    -0.0143      0.002     -6.809      0.000      -0.018      -0.010\n",
       "cluster_A_y            200.1053     24.200      8.269      0.000     152.674     247.537\n",
       "cluster_B_y            219.0014     24.216      9.044      0.000     171.538     266.465\n",
       "cluster_C_y            216.0048     24.263      8.903      0.000     168.450     263.560\n",
       "cluster_D_y            228.0829     24.325      9.377      0.000     180.407     275.759\n",
       "agility_y               31.5231      0.186    169.918      0.000      31.160      31.887\n",
       "==============================================================================\n",
       "Omnibus:                     1575.065   Durbin-Watson:                   1.843\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2442.595\n",
       "Skew:                           0.139   Prob(JB):                         0.00\n",
       "Kurtosis:                       3.652   Cond. No.                     3.43e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 3.43e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df=df_123.copy()\n",
    "copy1_df=df_123.copy()\n",
    "x_df=df_123.drop([\"ranking_y\"],axis=1)\n",
    "y_df=copy_df[\"ranking_y\"]\n",
    "X_df=x_df.iloc[:,1:]\n",
    "\n",
    "X_df=sm.add_constant(X_df)\n",
    "model = sm.OLS(y_df,X_df.astype(float)).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc rmse\n",
    "y_pred = model.predict(X_df)\n",
    "rms = sqrt(mean_squared_error(y_df, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg1=x_df.iloc[:, np.r_[2:16,31]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>ranking_y</td>    <th>  R-squared:         </th>  <td>   0.193</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.193</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   1859.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 06 Jun 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>19:29:41</td>     <th>  Log-Likelihood:    </th> <td>-3.9498e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>116478</td>      <th>  AIC:               </th>  <td>7.900e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>116462</td>      <th>  BIC:               </th>  <td>7.901e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    15</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>              <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                <td>   16.0824</td> <td>    0.060</td> <td>  269.278</td> <td> 0.000</td> <td>   15.965</td> <td>   16.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_2_x</th>        <td>   -1.6596</td> <td>    0.094</td> <td>  -17.574</td> <td> 0.000</td> <td>   -1.845</td> <td>   -1.475</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_3_x</th>        <td>   -3.2666</td> <td>    0.126</td> <td>  -25.861</td> <td> 0.000</td> <td>   -3.514</td> <td>   -3.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance1_4_x</th>        <td>   -0.6948</td> <td>    0.083</td> <td>   -8.345</td> <td> 0.000</td> <td>   -0.858</td> <td>   -0.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_3_x</th>        <td>   -0.6533</td> <td>    0.099</td> <td>   -6.628</td> <td> 0.000</td> <td>   -0.846</td> <td>   -0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance2_4_x</th>        <td>   -1.9461</td> <td>    0.114</td> <td>  -17.047</td> <td> 0.000</td> <td>   -2.170</td> <td>   -1.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance3_4_x</th>        <td>   -1.7387</td> <td>    0.070</td> <td>  -24.695</td> <td> 0.000</td> <td>   -1.877</td> <td>   -1.601</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid1_x</th> <td>    2.1756</td> <td>    0.043</td> <td>   50.973</td> <td> 0.000</td> <td>    2.092</td> <td>    2.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid2_x</th> <td>    0.3351</td> <td>    0.066</td> <td>    5.047</td> <td> 0.000</td> <td>    0.205</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid3_x</th> <td>    1.1267</td> <td>    0.081</td> <td>   13.919</td> <td> 0.000</td> <td>    0.968</td> <td>    1.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>distance_centroid4_x</th> <td>    0.7622</td> <td>    0.058</td> <td>   13.054</td> <td> 0.000</td> <td>    0.648</td> <td>    0.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_A_x</th>          <td>   -0.8601</td> <td>    1.369</td> <td>   -0.628</td> <td> 0.530</td> <td>   -3.543</td> <td>    1.823</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_B_x</th>          <td>  -32.1937</td> <td>    1.281</td> <td>  -25.128</td> <td> 0.000</td> <td>  -34.705</td> <td>  -29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_C_x</th>          <td>    3.6201</td> <td>    1.100</td> <td>    3.292</td> <td> 0.001</td> <td>    1.465</td> <td>    5.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cluster_D_x</th>          <td>   13.1718</td> <td>    1.230</td> <td>   10.707</td> <td> 0.000</td> <td>   10.761</td> <td>   15.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>agility_y</th>            <td>   22.3010</td> <td>    0.178</td> <td>  125.179</td> <td> 0.000</td> <td>   21.952</td> <td>   22.650</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>977.498</td> <th>  Durbin-Watson:     </th> <td>   1.789</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1007.655</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.219</td>  <th>  Prob(JB):          </th> <td>1.55e-219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.127</td>  <th>  Cond. No.          </th> <td>    353.</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:              ranking_y   R-squared:                       0.193\n",
       "Model:                            OLS   Adj. R-squared:                  0.193\n",
       "Method:                 Least Squares   F-statistic:                     1859.\n",
       "Date:                Sat, 06 Jun 2020   Prob (F-statistic):               0.00\n",
       "Time:                        19:29:41   Log-Likelihood:            -3.9498e+05\n",
       "No. Observations:              116478   AIC:                         7.900e+05\n",
       "Df Residuals:                  116462   BIC:                         7.901e+05\n",
       "Df Model:                          15                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "========================================================================================\n",
       "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------\n",
       "const                   16.0824      0.060    269.278      0.000      15.965      16.199\n",
       "distance1_2_x           -1.6596      0.094    -17.574      0.000      -1.845      -1.475\n",
       "distance1_3_x           -3.2666      0.126    -25.861      0.000      -3.514      -3.019\n",
       "distance1_4_x           -0.6948      0.083     -8.345      0.000      -0.858      -0.532\n",
       "distance2_3_x           -0.6533      0.099     -6.628      0.000      -0.846      -0.460\n",
       "distance2_4_x           -1.9461      0.114    -17.047      0.000      -2.170      -1.722\n",
       "distance3_4_x           -1.7387      0.070    -24.695      0.000      -1.877      -1.601\n",
       "distance_centroid1_x     2.1756      0.043     50.973      0.000       2.092       2.259\n",
       "distance_centroid2_x     0.3351      0.066      5.047      0.000       0.205       0.465\n",
       "distance_centroid3_x     1.1267      0.081     13.919      0.000       0.968       1.285\n",
       "distance_centroid4_x     0.7622      0.058     13.054      0.000       0.648       0.877\n",
       "cluster_A_x             -0.8601      1.369     -0.628      0.530      -3.543       1.823\n",
       "cluster_B_x            -32.1937      1.281    -25.128      0.000     -34.705     -29.683\n",
       "cluster_C_x              3.6201      1.100      3.292      0.001       1.465       5.775\n",
       "cluster_D_x             13.1718      1.230     10.707      0.000      10.761      15.583\n",
       "agility_y               22.3010      0.178    125.179      0.000      21.952      22.650\n",
       "==============================================================================\n",
       "Omnibus:                      977.498   Durbin-Watson:                   1.789\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1007.655\n",
       "Skew:                           0.219   Prob(JB):                    1.55e-219\n",
       "Kurtosis:                       3.127   Cond. No.                         353.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_reg=sm.add_constant(reg1)\n",
    "model = sm.OLS(y_df,X_reg.astype(float)).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE -44.442 std 0.520\n",
      "Intercept -197.1042\n",
      "Coefficients  [ 2.41785771e-11  9.05772917e-02 -1.10287911e+00 -6.81508352e-02\n",
      "  3.34350140e-01  6.77269068e-01 -1.23155499e+00  3.71153765e-01\n",
      "  3.47890138e+00  1.18255153e+00 -1.35278847e+00  1.37902391e+00\n",
      "  1.16535398e+01 -5.35793649e+01 -3.51409862e+01 -3.38434173e+01\n",
      " -1.87281618e-01  8.52763677e-02  1.95044534e-02 -8.09742586e-03\n",
      "  3.13891608e-02  3.89093885e-02  1.43718595e-02 -2.47688685e-02\n",
      " -1.19171589e-02  6.25005567e-03 -1.43237491e-02  2.00105338e+02\n",
      "  2.19001386e+02  2.16004840e+02  2.28082881e+02  3.15231429e+01]\n",
      "MAE - Mean Absolute Error 5.490\n",
      "MSE - Mean Square Error  44.387\n",
      "R2    0.306\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LinearRegression()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Linear Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "# Create the DataFrames for plotting\n",
    "resall=pd.DataFrame()\n",
    "res_w1=pd.DataFrame()\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Lin\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)\n",
    "\n",
    "# Now lets use it in the same way than the statsmodel\n",
    "\n",
    "model_x=LinearRegression()\n",
    "model_x.fit(X_df,y_df)\n",
    "print(f'Intercept {model_x.intercept_:.4f}')\n",
    "print(\"Coefficients \",model_x.coef_)\n",
    "\n",
    "y_pred_x=model_x.predict(X_df)\n",
    "\n",
    "print(f'MAE - Mean Absolute Error {mean_absolute_error(y_df, y_pred_x):.3f}')\n",
    "print(f'MSE - Mean Square Error  {mean_squared_error(y_df, y_pred_x):.3f}')\n",
    "print(f'R2    {r2_score(y_df, y_pred_x):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE -44.459 std 0.527\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=Ridge()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Ridge Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Ridge\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - MSE -58.409 std 0.792\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=Lasso()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Lasso Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Lasso\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale between 0 and 1\n",
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "X_sc=scaler.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Regression - MSE -42.643 std 0.517\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=KNeighborsRegressor()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X_sc, y_df, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'KNN Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"KNN\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Trees Regression - MSE -63.283 std 0.819\n"
     ]
    }
   ],
   "source": [
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=DecisionTreeRegressor()\n",
    "scoring = \"neg_mean_squared_error\"\n",
    "\n",
    "results=cross_val_score(model, X_sc, y_df, cv=kfold, scoring=scoring)\n",
    "\n",
    "print(f'Decision Trees Regression - MSE {results.mean():.3f} std {results.std():.3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"Trees\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13237bd30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's compare them all \n",
    "plt.figure(figsize=(15,9))\n",
    "\n",
    "sns.boxplot(data=resall, x=\"Type\", y=\"Res\")\n",
    "\n",
    "sns.swarmplot(data=resall, x=\"Type\", y=\"Res\", color=\"royalblue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df['in Top 5']=np.where(copy_df['ranking_y']<=5, 'yes','no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df=copy_df.drop([\"ranking_y\",'in Top 5'],axis=1)\n",
    "y_df=copy_df['in Top 5']\n",
    "X_df=x_df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "std_scaler=preprocessing.StandardScaler()\n",
    "X_std=std_scaler.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_w1=pd.DataFrame()\n",
    "res_w2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy 79.178% std 0.220369\n",
      "Logistic Regression (-1..1) - Accuracy 79.084% std 0.242774\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'Logistic Regression - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'Logistic Regression (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "\n",
    "# if the range of variables is large scaling doesn't matter in a log regression \n",
    "# but if you are not sure if they are (or you don't want to check ... ) just try ! \n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"log\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"log -1..1\"\n",
    "\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes - Accuracy 47.114% std 0.352504\n",
      "Naive Bayes (-1..1) - Accuracy 47.129% std 0.355343\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=GaussianNB()\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'Naive Bayes - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'Naive Bayes (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"NB\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"NB -1..1\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy 75.526% std 0.299363\n",
      "Decision Tree (-1..1) - Accuracy 75.540% std 0.279513\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "model=DecisionTreeClassifier(class_weight=\"balanced\", random_state=seed)\n",
    "\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'Decision Tree - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'Decision Tree (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"DT\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"DT -1..1\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Linear Discriminant Analysis - Accuracy 79.212% std 0.209158\n",
      "LDA (-1..1) - Accuracy 79.212% std 0.209158\n"
     ]
    }
   ],
   "source": [
    "# LDA - Linear Discriminant Analysis               ##!!!!!!!!!!!!!!!! y L 3ADE AKHADD!!!!!!!!! y y y \n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LinearDiscriminantAnalysis()\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'LDA Linear Discriminant Analysis - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'LDA (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"LDA\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"LDA -1..1\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_df['in Top 3']=np.where(copy_df['ranking_y']<=3, 'yes','no')\n",
    "x_df=copy_df.drop([\"ranking_y\",'in Top 3'],axis=1)\n",
    "y_df=copy_df['in Top 3']\n",
    "X_df=x_df.iloc[:,1:]\n",
    "std_scaler=preprocessing.StandardScaler()\n",
    "X_std=std_scaler.fit_transform(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_w1=pd.DataFrame()\n",
    "res_w2=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "//anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - Accuracy 63.112% std 0.463581\n",
      "Logistic Regression (-1..1) - Accuracy 66.953% std 0.293536\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LogisticRegression(solver=\"liblinear\",class_weight=\"balanced\")\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'Logistic Regression - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'Logistic Regression (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"log\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"log -1..1\"\n",
    "\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Accuracy 82.617% std 0.307360\n",
      "Decision Tree (-1..1) - Accuracy 82.633% std 0.342758\n"
     ]
    }
   ],
   "source": [
    "# Decision Trees\n",
    "seed=7\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=seed)\n",
    "\n",
    "model=DecisionTreeClassifier(class_weight=\"balanced\", random_state=seed)\n",
    "\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'Decision Tree - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'Decision Tree (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"DT\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"DT -1..1\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Linear Discriminant Analysis - Accuracy 87.452% std 0.073271\n",
      "LDA (-1..1) - Accuracy 87.452% std 0.073271\n"
     ]
    }
   ],
   "source": [
    "# LDA - Linear Discriminant Analysis\n",
    "\n",
    "kfold=KFold(n_splits=10, random_state=7)\n",
    "\n",
    "model=LinearDiscriminantAnalysis()\n",
    "\n",
    "results=cross_val_score(model, X_df, y_df, cv=kfold)\n",
    "\n",
    "print(f'LDA Linear Discriminant Analysis - Accuracy {results.mean()*100:.3f}% std {results.std()*100:3f}')\n",
    "\n",
    "results_scl=cross_val_score(model, X_std, y_df, cv=kfold)\n",
    "\n",
    "print(f'LDA (-1..1) - Accuracy {results_scl.mean()*100:.3f}% std {results_scl.std()*100:3f}')\n",
    "\n",
    "\n",
    "res_w1[\"Res\"]=results\n",
    "res_w1[\"Type\"]=\"LDA\"\n",
    "\n",
    "res_w2[\"Res\"]=results_scl\n",
    "res_w2[\"Type\"]=\"LDA -1..1\"\n",
    "\n",
    "resall=pd.concat([resall,res_w1,res_w2], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
